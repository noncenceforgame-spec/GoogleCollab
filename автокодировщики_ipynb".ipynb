{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uj2KBqnxLlqxknyeu7Qq0KemqcvtTpZw",
      "authorship_tag": "ABX9TyO/bKlTf+D9VGfb4kcUYeeF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noncenceforgame-spec/GoogleCollab/blob/main/%D0%B0%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA%D0%B8_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6mL427zRARg"
      },
      "source": [
        "# Список доступных датасетов\n",
        "\n",
        "Эта ячейка выводит список некоторых датасетов, доступных в библиотеке `torchvision.datasets`, которые могут быть автоматически загружены."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "print(\"Список некоторых датасетов из torchvision.datasets, доступных для автоматической загрузки:\")\n",
        "\n",
        "# Список некоторых классов датасетов, которые обычно поддерживают download=True\n",
        "downloadable_datasets = [\n",
        "    'MNIST',\n",
        "    'FashionMNIST',\n",
        "    'KMNIST',\n",
        "    'EMNIST',\n",
        "    'QMNIST',\n",
        "    'CIFAR10',\n",
        "    'CIFAR100',\n",
        "    'SVHN',\n",
        "    'STL10',\n",
        "    'FakeData', # Это синтетический датасет, но доступен через API\n",
        "    'USPS',\n",
        "    'VOCSegmentation', # Доступен для загрузки\n",
        "    'VOCDetection' # Доступен для загрузки\n",
        "]\n",
        "\n",
        "for ds_name in downloadable_datasets:\n",
        "    try:\n",
        "        # Проверяем наличие класса датасета по имени\n",
        "        ds_class = getattr(datasets, ds_name, None)\n",
        "        if ds_class is not None:\n",
        "             print(f\"- {ds_name}\")\n",
        "        # else:\n",
        "        #     print(f\"- {ds_name} (класс не найден, возможно, недоступен в этой версии)\") # Оставляем только найденные\n",
        "    except Exception as e:\n",
        "        print(f\"- {ds_name} (ошибка при проверке: {e})\")\n",
        "\n",
        "print(\"\\nПримечание: Полный список с деталями доступен в официальной документации по ссылке.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5es_u8IGmzD",
        "outputId": "e2a09368-c0ed-4741-bcab-db6af47c7f09",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Список некоторых датасетов из torchvision.datasets, доступных для автоматической загрузки:\n",
            "- MNIST\n",
            "- FashionMNIST\n",
            "- KMNIST\n",
            "- EMNIST\n",
            "- QMNIST\n",
            "- CIFAR10\n",
            "- CIFAR100\n",
            "- SVHN\n",
            "- STL10\n",
            "- FakeData\n",
            "- USPS\n",
            "- VOCSegmentation\n",
            "- VOCDetection\n",
            "\n",
            "Примечание: Полный список с деталями доступен в официальной документации по ссылке.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dba83284"
      },
      "source": [
        "# Загрузка CIFAR10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Определение трансформаций (преобразование к тензору и нормализация)\n",
        "# Эти трансформации соответствуют тем, что часто используются для CIFAR10\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Пример нормализации\n",
        "])\n",
        "\n",
        "# Загрузка тренировочной части датасета CIFAR10\n",
        "# download=True скачает датасет, если он еще не загружен\n",
        "try:\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    print(f\"Тренировочный датасет CIFAR10 успешно загружен. Размер датасета: {len(trainset)}\")\n",
        "\n",
        "    # Загрузка тестовой части датасета CIFAR10\n",
        "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    print(f\"Тестовый датасет CIFAR10 успешно загружен. Размер датасета: {len(testset)}\")\n",
        "\n",
        "    # Пример доступа к элементу тренировочного датасета\n",
        "    image, label = trainset[0]\n",
        "    print(f\"Тип изображения: {type(image)}, Размер изображения: {image.shape}\")\n",
        "    print(f\"Тип метки: {type(label)}, Метка: {label}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке датасета CIFAR10: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqEB0GHKgaba",
        "outputId": "98bdecde-dbad-48a9-d0c1-84cdd127f80a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 26.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тренировочный датасет CIFAR10 успешно загружен. Размер датасета: 50000\n",
            "Тестовый датасет CIFAR10 успешно загружен. Размер датасета: 10000\n",
            "Тип изображения: <class 'torch.Tensor'>, Размер изображения: torch.Size([3, 32, 32])\n",
            "Тип метки: <class 'int'>, Метка: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3b6b923"
      },
      "source": [
        "# Просмотр примеров изображений из CIFAR10\n",
        "\n",
        "Эта ячейка содержит код для отображения нескольких примеров изображений из датасета CIFAR10 вместе с их метками."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "11c055cd",
        "outputId": "9e979776-a521-4808-8bf6-eac8bff7d5c6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision # Импортируем torchvision\n",
        "import torch # Импортируем torch\n",
        "\n",
        "# Функция для отображения изображения\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # денормализация\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Получение нескольких случайных тренировочных изображений с помощью DataLoader\n",
        "# Убедитесь, что trainset определен из предыдущей ячейки\n",
        "try:\n",
        "    # Создаем DataLoader для получения пакета данных\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    # Отображение изображений\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "    # Вывод меток классов\n",
        "    classes = ('plane', 'car', 'bird', 'cat',\n",
        "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "\n",
        "except NameError:\n",
        "    print(\"Ошибка: Датасет 'trainset' не найден. Пожалуйста, убедитесь, что предыдущая ячейка с загрузкой датасета была успешно выполнена.\")\n",
        "except Exception as e:\n",
        "    print(f\"Произошла ошибка: {e}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "truck ship  dog   ship \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка данных для обучения VGG и Resnet"
      ],
      "metadata": {
        "id": "t8LPSNmkjX_L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3231d8fb"
      },
      "source": [
        "### Определение трансформаций данных\n",
        "\n",
        "Для подготовки данных к обучению моделей VGG и ResNet, которые обычно ожидают входные изображения размером 224x224 пикселя и используют стандартизированную нормализацию (часто с использованием средних значений и стандартных отклонений датасета ImageNet), мы определим соответствующие трансформации. Для тренировочного набора данных будут добавлены аугментации для улучшения обобщающей способности модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00766f12",
        "outputId": "75dc87ed-dc95-40f2-df8f-5419a1002488"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Определим трансформации для тренировочного набора данных с аугментацией\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),          # Изменение размера изображения до 256x256\n",
        "    transforms.RandomCrop(224),      # Случайная обрезка до 224x224\n",
        "    transforms.RandomHorizontalFlip(), # Случайное горизонтальное отражение\n",
        "    transforms.ToTensor(),           # Преобразование в тензор\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Нормализация ImageNet\n",
        "])\n",
        "\n",
        "# Определим трансформации для тестового набора данных (без аугментации)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),          # Изменение размера изображения до 256x256\n",
        "    transforms.CenterCrop(224),      # Обрезка центральной части до 224x224\n",
        "    transforms.ToTensor(),           # Преобразование в тензор\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Нормализация ImageNet\n",
        "])\n",
        "\n",
        "print(\"Трансформации данных определены.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Трансформации данных определены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание Dataloaders"
      ],
      "metadata": {
        "id": "9xxOxvGsn1Qt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a277bc83",
        "outputId": "cf4dfdfe-4835-48ea-aaa0-c001b5ca11a5"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Создание датасетов с применением новых трансформаций\n",
        "# Убедитесь, что trainset и testset определены из предыдущих ячеек\n",
        "try:\n",
        "    trainset_transformed = datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=train_transform)\n",
        "    testset_transformed = datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=test_transform)\n",
        "\n",
        "    # Определение DataLoader'ов\n",
        "    trainloader_transformed = torch.utils.data.DataLoader(trainset_transformed, batch_size=100,\n",
        "                                                          shuffle=True, num_workers=2)\n",
        "\n",
        "    testloader_transformed = torch.utils.data.DataLoader(testset_transformed, batch_size=100,\n",
        "                                                         shuffle=False, num_workers=2)\n",
        "\n",
        "    print(\"Даталоадеры для тренировочного и тестового наборов данных успешно созданы.\")\n",
        "    print(f\"Количество батчей в тренировочном даталоадере: {len(trainloader_transformed)}\")\n",
        "    print(f\"Количество батчей в тестовом даталоадере: {len(testloader_transformed)}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"Ошибка: Датасеты 'trainset' или 'testset' не найдены. Пожалуйста, убедитесь, что предыдущие ячейки были успешно выполнены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Произошла ошибка при создании даталоадеров: {e}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Даталоадеры для тренировочного и тестового наборов данных успешно созданы.\n",
            "Количество батчей в тренировочном даталоадере: 500\n",
            "Количество батчей в тестовом даталоадере: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0c9469d"
      },
      "source": [
        "# Task\n",
        "Определить модели VGG16 и ResNet18 с предварительно обученными весами, адаптировать их для классификации 10 классов CIFAR10, описать архитектуры и результаты на русском языке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "664453ae"
      },
      "source": [
        "## Определение моделей\n",
        "\n",
        "### Subtask:\n",
        "Создать ячейки кода для определения моделей VGG16 и ResNet18 с использованием предварительно обученных весов (pre-trained).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "16c0ca62",
        "outputId": "5f594689-bd5d-46f0-bed7-06ff37f4da62"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Define VGG16 model with pre-trained weights\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "print(\"VGG16 model with pre-trained weights defined.\")\n",
        "\n",
        "# Define ResNet18 model with pre-trained weights\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "print(\"ResNet18 model with pre-trained weights defined.\")\n",
        "\n",
        "# Print the models to verify they are loaded\n",
        "print(\"\\nVGG16 model architecture:\")\n",
        "print(vgg16)\n",
        "\n",
        "print(\"\\nResNet18 model architecture:\")\n",
        "print(resnet18)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 528M/528M [00:03<00:00, 161MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG16 model with pre-trained weights defined.\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet18 model with pre-trained weights defined.\n",
            "\n",
            "VGG16 model architecture:\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "ResNet18 model architecture:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c29435d"
      },
      "source": [
        "## Адаптация моделей для cifar10\n",
        "\n",
        "### Subtask:\n",
        "Изменить финальные слои моделей VGG16 и ResNet18, чтобы они подходили для классификации 10 классов датасета CIFAR10.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07ba6af4",
        "outputId": "a9545bae-29cf-40a5-cdcd-0ba2a30d32d2"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define the number of output classes for CIFAR10\n",
        "num_classes = 10\n",
        "\n",
        "# Modify the final layer of VGG16\n",
        "# VGG16's classifier is a sequence of linear layers\n",
        "# The last linear layer is vgg16.classifier[6]\n",
        "num_ftrs_vgg = vgg16.classifier[6].in_features\n",
        "vgg16.classifier[6] = nn.Linear(num_ftrs_vgg, num_classes)\n",
        "\n",
        "# Modify the final layer of ResNet18\n",
        "# ResNet18's final layer is a fully connected layer named 'fc'\n",
        "num_ftrs_resnet = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(num_ftrs_resnet, num_classes)\n",
        "\n",
        "print(\"Final layers of VGG16 and ResNet18 modified for 10 classes.\")\n",
        "\n",
        "# Print the modified final layers to verify\n",
        "print(\"\\nModified final layer of VGG16:\")\n",
        "print(vgg16.classifier[6])\n",
        "\n",
        "print(\"\\nModified final layer of ResNet18:\")\n",
        "print(resnet18.fc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final layers of VGG16 and ResNet18 modified for 10 classes.\n",
            "\n",
            "Modified final layer of VGG16:\n",
            "Linear(in_features=4096, out_features=10, bias=True)\n",
            "\n",
            "Modified final layer of ResNet18:\n",
            "Linear(in_features=512, out_features=10, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7266c3"
      },
      "source": [
        "## Описание моделей\n",
        "\n",
        "### Subtask:\n",
        "Предоставить описание архитектур VGG и ResNet на русском языке в markdown ячейках.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nXT_0JIepemO",
        "outputId": "ca88bd54-7679-43fb-b551-c03d34429b00"
      },
      "source": [
        "%%markdown\n",
        "# Описание архитектуры VGG\n",
        "\n",
        "Архитектура VGG (Visual Geometry Group) - это сверточная нейронная сеть, разработанная в Оксфордском университете. Ее ключевая особенность заключается в использовании очень маленьких сверточных ядер размера 3x3 на протяжении всей сети. Вместо использования больших ядер (например, 7x7 или 11x11), VGG использует несколько последовательных слоев с ядром 3x3, что позволяет достичь того же рецептивного поля, но с меньшим количеством параметров и большим количеством нелинейных преобразований.\n",
        "\n",
        "Другой важной чертой VGG является последовательное увеличение количества фильтров (каналов) после каждого пулингового слоя, что позволяет сети улавливать все более сложные признаки по мере углубления.\n",
        "\n",
        "Использование предварительно обученных весов (полученных на больших датасетах, таких как ImageNet) является стандартной практикой при работе с архитектурой VGG для задач классификации. Эти веса содержат информацию о низкоуровневых и среднеуровневых признаках, которые могут быть эффективно перенесены на новые задачи, такие как классификация изображений CIFAR10, даже если новый датасет меньше исходного. Адаптация для CIFAR10 включает замену финального классификационного слоя для соответствия количеству классов (10 в случае CIFAR10)."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Описание архитектуры VGG\n\nАрхитектура VGG (Visual Geometry Group) - это сверточная нейронная сеть, разработанная в Оксфордском университете. Ее ключевая особенность заключается в использовании очень маленьких сверточных ядер размера 3x3 на протяжении всей сети. Вместо использования больших ядер (например, 7x7 или 11x11), VGG использует несколько последовательных слоев с ядром 3x3, что позволяет достичь того же рецептивного поля, но с меньшим количеством параметров и большим количеством нелинейных преобразований.\n\nДругой важной чертой VGG является последовательное увеличение количества фильтров (каналов) после каждого пулингового слоя, что позволяет сети улавливать все более сложные признаки по мере углубления.\n\nИспользование предварительно обученных весов (полученных на больших датасетах, таких как ImageNet) является стандартной практикой при работе с архитектурой VGG для задач классификации. Эти веса содержат информацию о низкоуровневых и среднеуровневых признаках, которые могут быть эффективно перенесены на новые задачи, такие как классификация изображений CIFAR10, даже если новый датасет меньше исходного. Адаптация для CIFAR10 включает замену финального классификационного слоя для соответствия количеству классов (10 в случае CIFAR10).\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e276d20c",
        "outputId": "607f9915-af05-4bab-b29d-80c1cafd5767"
      },
      "source": [
        "%%markdown\n",
        "# Описание архитектуры ResNet\n",
        "\n",
        "ResNet (Residual Network) - это инновационная архитектура сверточных нейронных сетей, разработанная для решения проблемы затухания градиента в очень глубоких сетях. Ключевая идея ResNet заключается в использовании \"остаточных соединений\" (residual connections) или \"shortcuts\", которые позволяют напрямую передавать входные данные блока к его выходу, минуя один или несколько сверточных слоев.\n",
        "\n",
        "Математически, вместо того чтобы учиться отображению H(x) (где x - вход блока), блок учится отображению F(x) = H(x) - x. Тогда выход блока становится F(x) + x. Если оптимальное отображение близко к тождественному (т.е., H(x) ≈ x), то остаточное отображение F(x) будет близко к нулю, и сети будет легче оптимизировать небольшие изменения, чем учить тождественное отображение с нуля. Это позволяет строить гораздо более глубокие сети без существенной деградации производительности из-за проблем с градиентами.\n",
        "\n",
        "Как и в случае с VGG, для задач классификации на небольших датасетах, таких как CIFAR10, часто используют предварительно обученные на ImageNet веса ResNet. Эти веса предоставляют хорошую отправную точку, а финальный полносвязный слой адаптируется под количество классов целевого датасета."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Описание архитектуры ResNet\n\nResNet (Residual Network) - это инновационная архитектура сверточных нейронных сетей, разработанная для решения проблемы затухания градиента в очень глубоких сетях. Ключевая идея ResNet заключается в использовании \"остаточных соединений\" (residual connections) или \"shortcuts\", которые позволяют напрямую передавать входные данные блока к его выходу, минуя один или несколько сверточных слоев.\n\nМатематически, вместо того чтобы учиться отображению H(x) (где x - вход блока), блок учится отображению F(x) = H(x) - x. Тогда выход блока становится F(x) + x. Если оптимальное отображение близко к тождественному (т.е., H(x) ≈ x), то остаточное отображение F(x) будет близко к нулю, и сети будет легче оптимизировать небольшие изменения, чем учить тождественное отображение с нуля. Это позволяет строить гораздо более глубокие сети без существенной деградации производительности из-за проблем с градиентами.\n\nКак и в случае с VGG, для задач классификации на небольших датасетах, таких как CIFAR10, часто используют предварительно обученные на ImageNet веса ResNet. Эти веса предоставляют хорошую отправную точку, а финальный полносвязный слой адаптируется под количество классов целевого датасета.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98f99c1a"
      },
      "source": [
        "## Функции для обучения и тестирования\n",
        "\n",
        "### Subtask:\n",
        "Создать ячейки кода с функциями для обучения и тестирования моделей.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e218a8c",
        "outputId": "59d90cf0-4e47-4608-c7b1-94455f083e4d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def train_model(model, trainloader, criterion, optimizer, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Trains the given model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model to train.\n",
        "        trainloader (torch.utils.data.DataLoader): DataLoader for the training data.\n",
        "        criterion (torch.nn.Module): The loss function.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer.\n",
        "        num_epochs (int): The number of training epochs.\n",
        "        device (torch.device): The device to use for training (cpu or gpu).\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:    # print every 100 mini-batches\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / 100:.4f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "def test_model(model, testloader, device):\n",
        "    \"\"\"\n",
        "    Tests the given model and calculates accuracy.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model to test.\n",
        "        testloader (torch.utils.data.DataLoader): DataLoader for the test data.\n",
        "        device (torch.device): The device to use for testing (cpu or gpu).\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model on the test set.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')\n",
        "    return accuracy\n",
        "\n",
        "print(\"Training and testing functions defined.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and testing functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce4600e5"
      },
      "source": [
        "## Обучение моделей\n",
        "\n",
        "Обучить определенные модели VGG16 и ResNet18 на тренировочном наборе данных CIFAR10.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ba07b06",
        "outputId": "748aa348-6692-44c7-e477-497fdf644a6f"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 1. Determine the device to use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 2. Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"Loss function (CrossEntropyLoss) defined.\")\n",
        "\n",
        "# 3. Define optimizers for each model\n",
        "# For this example, we will train all parameters\n",
        "optimizer_vgg16 = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_resnet18 = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)\n",
        "print(\"Optimizers (SGD) defined for VGG16 and ResNet18.\")\n",
        "\n",
        "\n",
        "# 4. Set the number of epochs for training\n",
        "num_epochs = 1 # Keep epochs low for demonstration\n",
        "\n",
        "print(f\"Number of epochs set to: {num_epochs}\")\n",
        "\n",
        "# 5. Train the VGG16 model\n",
        "print(\"\\nStarting training for VGG16...\")\n",
        "train_model(vgg16, trainloader_transformed, criterion, optimizer_vgg16, num_epochs, device)\n",
        "\n",
        "# 6. Train the ResNet18 model\n",
        "print(\"\\nStarting training for ResNet18...\")\n",
        "train_model(resnet18, trainloader_transformed, criterion, optimizer_resnet18, num_epochs, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Loss function (CrossEntropyLoss) defined.\n",
            "Optimizers (SGD) defined for VGG16 and ResNet18.\n",
            "Number of epochs set to: 1\n",
            "\n",
            "Starting training for VGG16...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4377a8de"
      },
      "source": [
        "## Тестирование моделей\n",
        "\n",
        "### Subtask:\n",
        "Оценить производительность обученных моделей на тестовом наборе данных CIFAR10.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55a148b1"
      },
      "source": [
        "# Evaluate VGG16 model\n",
        "print(\"\\nEvaluating VGG16 model on the test set...\")\n",
        "vgg16_accuracy = test_model(vgg16, testloader_transformed, device)\n",
        "\n",
        "# Evaluate ResNet18 model\n",
        "print(\"\\nEvaluating ResNet18 model on the test set...\")\n",
        "resnet18_accuracy = test_model(resnet18, testloader_transformed, device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}